{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - Group #24\n",
    "## 1) Does basic house information reflect house's description?\n",
    "\n",
    "Our goal is to implement two clustering and compare the results. We create two datasets and each of them will be filled by data that we scraped.\n",
    "\n",
    "First of all, we import the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/robertapassarelli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time # For time.sleep() method\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk # To remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import string # To remove punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping\n",
    "To create the dataset we have to scrape the website of [Immobiliare.it](https://www.immobiliare.it) using **Beautiful Soup** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start : Wed Dec  5 21:55:33 2018\n",
      "End : Wed Dec  5 21:56:19 2018\n"
     ]
    }
   ],
   "source": [
    "print (\"Start : %s\" % time.ctime())\n",
    "numb_pag = 1\n",
    "df1 = pd.DataFrame(columns=['Price','Locali','Superficie','Bagni','Piano','Descrizione'] )\n",
    "i = 1\n",
    "\n",
    "while i <= numb_pag:\n",
    "    url = \"https://www.immobiliare.it/vendita-case/roma/?criterio=rilevanza&pag=\"+str(i)\n",
    "    html = urlopen(url)\n",
    "    time.sleep(3) # to prevent the website block\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    all_links = soup.find_all('a')\n",
    "    \n",
    "    links = []\n",
    "    for link in all_links:\n",
    "        if link.get('href')!= None:\n",
    "            links.append(link.get(\"href\")) # list with all links\n",
    "\n",
    "    for item in links:\n",
    "        if item[-4:] == 'html' and item[0:5] == 'https':\n",
    "            site = urlopen(item)\n",
    "            soup = BeautifulSoup(site, 'lxml')\n",
    "            data = soup.find_all(\"ul\", {'class': \"list-inline list-piped features__list\"})\n",
    "            price = soup.find_all(\"ul\", {'class':\"list-inline features__price-block\"})\n",
    "            description = soup.find_all(\"div\",{'class':\"col-xs-12 description-text text-compressed\"})\n",
    "            try:\n",
    "                pr = price[0].contents[0].get_text().replace(\"â‚¬\",\"\")\n",
    "                loc = data[0].contents[0].get_text().replace(\"\\xa0\",\"\").replace(\"+\", \"\").replace(\"locali\", \"\").strip()\n",
    "                mq = data[0].contents[1].get_text().replace(\"da \",\"\").replace(\"\\xa0m2\",\"\").replace(\"superficie\",\"\").replace(\"m2\",\"\").strip()\n",
    "                bath = data[0].contents[2].get_text().replace(\"\\xa0\",\"\").replace(\"+\", \"\").replace(\"bagni\", \"\").strip()\n",
    "                floor = data[0].contents[3].get_text().replace(\"\\xa0\", \"\").replace(\"\\n\",\"\").replace(\"piano\",\"\").replace(\"T\",\"0\").strip()\n",
    "                # we replace the floor `T` (piano Terra) with the number zero\n",
    "                descr = description[0].get_text()\n",
    "                l = [pr, loc, mq, bath, floor, descr]\n",
    "                # print(l)\n",
    "                df = pd.DataFrame([l], columns=['Price','Locali','Superficie','Bagni','Piano','Descrizione'])\n",
    "                df1 = pd.concat([df1, df], ignore_index=True) \n",
    "            except:\n",
    "                pass\n",
    "    i += 1\n",
    "print (\"End : %s\" % time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean the data:\n",
    "- replace `\\n` character in the announcement's description with an empty space\n",
    "- drop all the announcements that don't have an integer for the `floor`\n",
    "- remove the point in the price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['Piano'].apply(lambda x: str(x).isdigit() )]\n",
    "df1['Descrizione'] = df1['Descrizione'].str.replace(r'\\n', ' ', regex=True)\n",
    "\n",
    "df1['Price'] = df1['Price'].astype(str).str.strip()\n",
    "df1['Price'] = df1['Price'].str.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Locali</th>\n",
       "      <th>Superficie</th>\n",
       "      <th>Bagni</th>\n",
       "      <th>Piano</th>\n",
       "      <th>Descrizione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225000</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PAPILLO EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Vendesi appa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>574000</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Vendesi appa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500000</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Vendesi appa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>425000</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Vendesi appa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price Locali Superficie Bagni Piano  \\\n",
       "0  225000      2         50     1     1   \n",
       "1  300000      2         46     1     4   \n",
       "2  574000      4         89     2     5   \n",
       "3  500000      3         89     2     3   \n",
       "4  425000      3         72     2     4   \n",
       "\n",
       "                                         Descrizione  \n",
       "0                                    PAPILLO EUR ...  \n",
       "1                                    Vendesi appa...  \n",
       "2                                    Vendesi appa...  \n",
       "3                                    Vendesi appa...  \n",
       "4                                    Vendesi appa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the description in a `.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = list(df1.Descrizione)\n",
    "with open('data/description.txt', 'w') as file:\n",
    "     file.write(json.dumps(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Information\n",
    "The first matrix `matrix1` is $m_{ij} = value$, where $i \\in \\{announcement_1, ..., announcement_n\\}$ ($n$ is the number of announcement) and $j \\in \\{price, locali, superficie, bagni, piano \\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Locali</th>\n",
       "      <th>Superficie</th>\n",
       "      <th>Bagni</th>\n",
       "      <th>Piano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225000</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>574000</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500000</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>425000</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price Locali Superficie Bagni Piano\n",
       "0  225000      2         50     1     1\n",
       "1  300000      2         46     1     4\n",
       "2  574000      4         89     2     5\n",
       "3  500000      3         89     2     3\n",
       "4  425000      3         72     2     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1 = df1[['Price', 'Locali', 'Superficie', 'Bagni', 'Piano']]\n",
    "matrix1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Description\n",
    "The second matrix `matrix2` is $m_{ij} = \\text{tfIdf}_{ij}$ where $i \\in \\{announcement_1, ..., announcement_n\\}$ and $j \\in \\{word_1, ...,word_m\\}$, with $n$ number of the announcements and $m$ is the cardinality of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the `.txt` file with the descriptions\n",
    "with open('data/description.txt')as f: \n",
    "    description = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean the descriptions:\n",
    "- remove stopwords \n",
    "- remove punctuation\n",
    "- stemming\n",
    "\n",
    "Define a dictionary `clean_descr` with the structure:\n",
    "- key: number of announcement\n",
    "- value: cleaned word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('italian')) # set of stopwords\n",
    "stemmer = nltk.stem.snowball.ItalianStemmer() # italian stemmer\n",
    "punctuation = set(string.punctuation) # set of punctuation\n",
    "\n",
    "clean_descr = {}  \n",
    "\n",
    "for i, row in df1[:].iterrows():\n",
    "    # Turn the string in lowercase letter and remove the stopwords and non-alphabetic words\n",
    "    newrow = row.Descrizione\n",
    "    text = ([w.lower() for w in list(newrow.split(' ')) \n",
    "             if w.lower() not in stop_words and w.isalpha()])\n",
    "    # To remove punctuation considering character by character\n",
    "    l = []\n",
    "    for word in text:\n",
    "        word = ''.join(ch for ch in word if ch not in punctuation)\n",
    "        l.append(word)\n",
    "    # Stem the words and put in a dict\n",
    "    clean_descr[i] = [stemmer.stem(w) for w in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create`vocabulary` like a dictionary of the words contained in all the documents that maps each word to an integer, with the structure:\n",
    "- key: word\n",
    "- value: number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {} # vocabulary as a dictionary\n",
    "i = 0\n",
    "\n",
    "for idx in range(len(clean_descr)):\n",
    "    for word in list(clean_descr.values())[idx]:\n",
    "        if word not in vocabulary.keys():\n",
    "            vocabulary[word] = i\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/vocabulary.txt', 'w') as file:\n",
    "     file.write(json.dumps(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily proceed with the `inverted index`, a dictionary with:\n",
    "- key: number that correspond to the value in the vocabulary\n",
    "- value: number of document in which there is the word which corresponds to the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted index \n",
    "inverted_d = {} # empty dict \n",
    "\n",
    "for key, value in clean_descr.items():\n",
    "    for i in sorted(list(set(value))):\n",
    "        if (vocabulary[i] in inverted_d):\n",
    "            inverted_d[vocabulary[i]] = inverted_d[vocabulary[i]] + [key]\n",
    "        else:\n",
    "            inverted_d[vocabulary[i]] = [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/inverted_d.txt', 'w') as file:\n",
    "     file.write(json.dumps(inverted_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to calculate the **TF-IDF** of all the words, that is defined as the \"term frequency\" times the \"inverse document frequency\" where:\n",
    "- \"term frequency\" is the ratio between the number of the term occurencies in the document and the total number of words in the document;\n",
    "- \"inverse document frequency\" is the logarithm of the ratio between the total number of documents and the number of documents containing the term (plus 1 to avoid division by zero).\n",
    "\n",
    "IDF is indipendent from the specific document, thus we can calculate it once and use it when we need it. Each term will have a single IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA QUI NON HO PROVATO! Ã¨ DEL PRECEDENTE HW, QUALCHE MODIFICA FORSE VA FATTA\n",
    "idf = {}\n",
    "n_doc = len(clean_descr)\n",
    "\n",
    "for term_id, doc in inverted_d.items():\n",
    "    idf[term_id] = pd.np.log(n_doc/(1+len(doc)))\n",
    "    \n",
    "# inverted index \n",
    "tfidf_inverted_d = {} # empty dict \n",
    "\n",
    "for key, value in clean_descr.items():\n",
    "    for i in sorted(list(set(value))):\n",
    "        if (vocabulary[i] in tfidf_inverted_d):\n",
    "            tfidf_inverted_d[vocabulary[i]] = tfidf_inverted_d[vocabulary[i]] + [(key, (value.count(i)/len(value)) * idf[vocabulary[i]])]\n",
    "        else:\n",
    "            tfidf_inverted_d[vocabulary[i]] = [(key, (value.count(i)/len(value)) * idf[vocabulary[i]])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTA ERA LA TUA FUNZIONE\n",
    "\n",
    "#functions defined in order to calculate the tfIdf coefficient\n",
    "def N(df1):\n",
    "    #number of documents in the collection\n",
    "    return len(df1)\n",
    "\n",
    "def df_t(word, df1):\n",
    "    #number of documents in the collection that contain a term t\n",
    "    counter=0\n",
    "    for lista in df1:\n",
    "        if word in lista:\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def tf_t_d(word,lista):\n",
    "    #term frequency:number of ocurrence of term t in document d\n",
    "    return lista.count(word)\n",
    "\n",
    "def id_f_t(word, df1):\n",
    "    #inverse document frequency of a term t\n",
    "    return log(len(df1)/df_t(word, df1),10)\n",
    "\n",
    "def tf_idf(word,lista,df1):\n",
    "    #tf_idf of a term in a document of a collection N\n",
    "    return tf_t_d(word,lista)*id_f_t(word, df1)\n",
    "\n",
    "def inverted_index_creation_tfIdf(vocabulary, df1):  \n",
    "    #function that creates inverted_index with coefficient tfIdf from all the documents\n",
    "    inverted_index={}\n",
    "    n=1\n",
    "    \n",
    "    for lista in df1:          \n",
    "         #loop for each word of the document create a new key if the word is not in the dictionary \n",
    "         #add the number of the document to an existing key is the word is in the dictionary\n",
    "         #tfIdf coefficient of each term is also added\n",
    "        for word in set(lista):\n",
    "    \n",
    "            index=list(vocabulary.values())\n",
    "            if vocabulary[word] in list(inverted_index.keys()):\n",
    "                inverted_index[vocabulary[word]]=(inverted_index[vocabulary[word]])+[(\"announcement_\"+str(n),tf_idf(word,lista,df1))]\n",
    "            else:\n",
    "                inverted_index[int(vocabulary[word])]=[(\"announcement_\"+str(n),tf_idf(word,lista,df1))]\n",
    "        \n",
    "        n+=1\n",
    "\n",
    "    with open('data/inverted_index_tfIdf.tsv', 'w') as f1: #write the inverted index in a file called \"inverted_index_tfIdf.tsv\"\n",
    "        json.dump(inverted_index, f1)\n",
    "        f1.close()\n",
    "    return inverted_index \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
